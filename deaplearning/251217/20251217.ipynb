{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUeKliIQjL4k",
        "outputId": "b42bd30b-d0ae-4af5-cd0b-99e026e97ed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('./drive/MyDrive/apikeys.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "MDJXQ5dAoRIj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AsyncOpenAI, OpenAI\n",
        "\n",
        "sync_client = OpenAI()\n",
        "client = AsyncOpenAI()"
      ],
      "metadata": {
        "id": "GCKA111iobTZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_call(prompt: str,  model: str = \"gpt-4o-mini\") -> str:\n",
        "    messages = []\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    chat_completion = sync_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "rdCGrtOEorXf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def llm_call_async(prompt: str,  model: str = \"gpt-4o-mini\") -> str:\n",
        "    messages = []\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    chat_completion = await client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "    print(model,\"완료\")\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "jMjLf1cspBPW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def run_llm_parallel(prompt_list):\n",
        "    tasks = [llm_call_async(prompt) for prompt in prompt_list]\n",
        "    responses=[]\n",
        "    for task in asyncio.as_completed(tasks):\n",
        "        result = await task\n",
        "        responses.append(result)\n",
        "    return responses"
      ],
      "metadata": {
        "id": "SCBrxQpApyHg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"AI는 미래 일자리에 어떤 영향을 미칠까?\""
      ],
      "metadata": {
        "id": "lhWu3zs3qLc7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrator_prompt= f\"\"\"\n",
        "다음 사용자 질문을 분석하고, 이를 3개의 관련된 하위 질문으로 분해하십시오:\n",
        "\n",
        "다음 형식으로 응답을 제공하십시오:\n",
        "\n",
        "{{\n",
        "    \"analysis\": \"사용자 질문에 대한 이해를 상세히 설명하고, 작성한 하위 질문들의 근거를 설명하십시오.\",\n",
        "    \"subtasks\": [\n",
        "        {{\n",
        "            \"description\": \"이 하위 질문의 초점과 의도를 설명하십시오.\",\n",
        "            \"sub_question\": \"질문 1\"\n",
        "        }},\n",
        "        {{\n",
        "            \"description\": \"이 하위 질문의 초점과 의도를 설명하십시오.\",\n",
        "            \"sub_question\": \"질문 2\"\n",
        "        }}\n",
        "        // 필요에 따라 추가 하위 질문 포함\n",
        "    ]\n",
        "}}\n",
        "최대 3개의 하위 질문을 생성하세요\n",
        "\n",
        "사용자 질문: {user_query}\"\"\""
      ],
      "metadata": {
        "id": "bSFxSK6vqm7z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrator_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gD1l5fCGq1--",
        "outputId": "a6a1801d-6bdc-4897-bc63-1b3a50515aca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n다음 사용자 질문을 분석하고, 이를 3개의 관련된 하위 질문으로 분해하십시오:\\n\\n다음 형식으로 응답을 제공하십시오:\\n\\n{\\n    \"analysis\": \"사용자 질문에 대한 이해를 상세히 설명하고, 작성한 하위 질문들의 근거를 설명하십시오.\",\\n    \"subtasks\": [\\n        {\\n            \"description\": \"이 하위 질문의 초점과 의도를 설명하십시오.\",\\n            \"sub_question\": \"질문 1\"\\n        },\\n        {\\n            \"description\": \"이 하위 질문의 초점과 의도를 설명하십시오.\",\\n            \"sub_question\": \"질문 2\"\\n        }\\n        // 필요에 따라 추가 하위 질문 포함\\n    ]\\n}\\n최대 3개의 하위 질문을 생성하세요\\n\\n사용자 질문: AI는 미래 일자리에 어떤 영향을 미칠까?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrator_response = llm_call(orchestrator_prompt, model='gpt-4o')"
      ],
      "metadata": {
        "id": "RryYAH2usBCv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orchestrator_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "tzP9ptersPyi",
        "outputId": "f56fab65-5b0b-4004-c6b0-24b7bd61e4a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n    \"analysis\": \"사용자 질문은 AI가 미래의 고용 환경과 직업 시장에 미칠 영향을 이해하고자 하는 것에 초점을 맞추고 있습니다. AI의 발전은 직업의 성격을 변화시키고 새로운 직업을 창출하며 일부 직업을 대체할 수 있기 때문에 이에 대한 관심이 높아지고 있습니다. 하위 질문들은 AI가 일자리에 미치는 영향의 다양한 측면을 살펴보도록 구성되었습니다.\",\\n    \"subtasks\": [\\n        {\\n            \"description\": \"이 하위 질문은 AI가 어떤 유형의 일자리를 대체하거나 감소시킬 가능성이 있는지를 이해하는 데 초점을 맞춥니다. AI는 특히 반복적이고 예측 가능한 작업을 자동화하는 데 강점이 있기 때문에, 이러한 변화가 직업 시장에 어떤 영향을 미칠지 질문합니다.\",\\n            \"sub_question\": \"AI는 어떤 직업을 대체할 것인가?\"\\n        },\\n        {\\n            \"description\": \"이 하위 질문은 AI의 발달로 인해 새롭게 생성될 수 있는 일자리의 유형과 이러한 직업들이 요구하는 기술 및 자격에 대해 탐구하는 것입니다. 이를 통해 개인과 교육 기관이 미래의 일자리 요구에 대비할 수 있도록 합니다.\",\\n            \"sub_question\": \"AI로 인해 새롭게 창출될 일자리는 어떤 것들이 있을까?\"\\n        },\\n        {\\n            \"description\": \"이 하위 질문은 AI의 도입이 노동 시장의 구조적 변화를 유발할 것인가에 대해 질문합니다. 예를 들어 AI로 인한 실업률 변화나 일자리의 성격 변화 등이 어떻게 노동 시장 동향에 영향을 미칠 수 있는지를 살펴봅니다.\",\\n            \"sub_question\": \"AI는 노동 시장의 구조에 어떤 변화를 가져올 것인가?\"\\n        }\\n    ]\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_json=json.loads(orchestrator_response.replace('```json', '').replace('```',''))"
      ],
      "metadata": {
        "id": "crYcQD0MsYtI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZYi6aHeUs2Ie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}